{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "018c47c5-2e6a-45a0-8a50-d4e8382f6bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 911 entries, 0 to 910\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   birth   704 non-null    object\n",
      " 1   death   595 non-null    object\n",
      " 2   gender  768 non-null    object\n",
      " 3   hair    172 non-null    object\n",
      " 4   height  98 non-null     object\n",
      " 5   name    911 non-null    object\n",
      " 6   race    771 non-null    object\n",
      " 7   realm   197 non-null    object\n",
      " 8   spouse  465 non-null    object\n",
      "dtypes: object(9)\n",
      "memory usage: 64.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\TH KÖLN\\Semester 5\\Daten Modellierung\\lotr_characters.csv\")\n",
    "\n",
    "# Step 1: Initial Inspection\n",
    "print(\"Initial Dataset Info:\\n\")\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f23e231-8a51-44dc-bc98-10ea97458a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved as 'lotr_characters_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Cleaning the Data\n",
    "# Remove rows with missing values in critical columns\n",
    "df_cleaned = df.dropna(subset=['birth', 'death', 'gender', 'name', 'race']).copy()\n",
    "\n",
    "# Standardize names: strip whitespace and convert to title case\n",
    "df_cleaned['name'] = df_cleaned['name'].str.strip().str.title()\n",
    "\n",
    "# Clean other columns\n",
    "columns_to_clean = ['birth', 'death', 'gender', 'race', 'realm', 'spouse']\n",
    "def clean_text(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    return re.sub(r'[^\\w\\s]', '', value.strip())\n",
    "\n",
    "df_cleaned[columns_to_clean] = df_cleaned[columns_to_clean].apply(lambda col: col.map(lambda x: clean_text(x) if isinstance(x, str) else x))\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv(r\"C:\\Users\\user\\Desktop\\TH KÖLN\\Semester 5\\Daten Modellierung\\lotr_characters_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned dataset saved as 'lotr_characters_cleaned.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9120456b-ae38-4b20-9717-7652f890919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Results:\n",
      "Total Rows in Dataset: 548\n"
     ]
    }
   ],
   "source": [
    "# Analysis: Total Rows and Unique Names\n",
    "# Count the total number of rows\n",
    "total_rows = len(df_cleaned)\n",
    "print(\"\\nAnalysis Results:\")\n",
    "print(f\"Total Rows in Dataset: {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a1ffe96-3c4c-4fb1-b2c6-0f413854007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Results:\n",
      "Total Rows in Dataset: 548\n",
      "Total Unique Names: 548\n",
      "\n",
      "Gender Distribution:\n",
      "gender\n",
      "Male                469\n",
      "Female               76\n",
      "Males                 1\n",
      "Most likely male      1\n",
      "male                  1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 Most Common Races:\n",
      "race\n",
      "Men        316\n",
      "Hobbits     83\n",
      "Elves       49\n",
      "Dwarves     34\n",
      "Ainur       21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analysis: Total Rows and Unique Names\n",
    "# Count the total number of rows\n",
    "total_rows = len(df_cleaned)\n",
    "\n",
    "# Count unique names\n",
    "unique_names = df_cleaned['name'].nunique()\n",
    "\n",
    "# Distribution of gender\n",
    "gender_distribution = df_cleaned['gender'].value_counts()\n",
    "\n",
    "# Top 5 most common races\n",
    "race_counts = df_cleaned['race'].value_counts().head(5)\n",
    "\n",
    "# Print analysis results\n",
    "print(\"\\nAnalysis Results:\")\n",
    "print(f\"Total Rows in Dataset: {total_rows}\")\n",
    "print(f\"Total Unique Names: {unique_names}\")\n",
    "print(\"\\nGender Distribution:\")\n",
    "print(gender_distribution)\n",
    "print(\"\\nTop 5 Most Common Races:\")\n",
    "print(race_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1d7a189-8d60-437e-b390-6d5695f1bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation: Markdown File\n",
    "documentation = f\"\"\"# Data Cleaning and Analysis Documentation\n",
    "\n",
    "## Cleaning Steps\n",
    "1. Loaded the dataset `lotr_characters.csv`.\n",
    "2. Inspected the dataset for missing or inconsistent data.\n",
    "3. Removed rows with missing values in critical columns: `birth`, `death`, `gender`, `name`, `race`.\n",
    "4. Standardized the `name` column by stripping whitespace and converting to title case.\n",
    "5. Cleaned other columns (`birth`, `death`, `gender`, `race`, `realm`, `spouse`) by removing non-alphanumeric characters and leading/trailing whitespace.\n",
    "6. Saved the cleaned dataset as `lotr_characters_cleaned.csv`.\n",
    "\n",
    "## Analysis Results\n",
    "### Total Rows in Dataset\n",
    "- {total_rows}\n",
    "\n",
    "### Total Unique Names\n",
    "- {unique_names}\n",
    "\n",
    "### Gender Distribution\n",
    "{gender_distribution.to_string()}\n",
    "\n",
    "### Top 5 Most Common Races\n",
    "{race_counts.to_string()}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15985e63-2ffb-4e09-ace5-50647d6239bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown documentation saved as 'data_cleaning.md'.\n"
     ]
    }
   ],
   "source": [
    "# Save the Markdown file\n",
    "with open(r\"C:\\Users\\user\\Desktop\\TH KÖLN\\Semester 5\\Daten Modellierung\\data_cleaning.md\", 'w') as f:\n",
    "    f.write(documentation)\n",
    "\n",
    "print(\"Markdown documentation saved as 'data_cleaning.md'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7769b-59e0-42e9-b45d-429fa92a9a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
